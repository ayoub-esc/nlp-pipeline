{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46e05db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ayoub/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "from transformers import TFXLNetModel, XLNetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef259fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "DATA_PATH = PATH + '/data/'\n",
    "MODEL_PATH = PATH + '/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211657da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlnet_model():\n",
    "\n",
    "    word_inputs = tf.keras.Input(shape=(128,), name='word_inputs', dtype='int32')\n",
    "    xlnet = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
    "    xlnet_encodings = xlnet(word_inputs)[0]\n",
    "    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n",
    "    doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax', name='outputs')(doc_encoding)\n",
    "    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39feaa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer, max_len=128):\n",
    "    inps = [tokenizer.encode_plus(t, max_length=max_len, truncation=True, padding='max_length', add_special_tokens=True) for t in text]\n",
    "    inp_tok = np.array([a['input_ids'] for a in inps])\n",
    "    ids = np.array([a['attention_mask'] for a in inps])\n",
    "    segments = np.array([a['token_type_ids'] for a in inps])\n",
    "    return inp_tok, ids, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57bb46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d926a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 06:33:16.262869: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-09 06:33:16.263279: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x106093280>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x106093280>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "xlnet = xlnet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f265b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/8tsm_sd976ncj2_t1ky1vqlh0000gn/T/ipykernel_2530/1287677941.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test['text'] = df_test['text'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "#df_train = pd.read_csv(DATA_PATH+'train.csv')\n",
    "#df_train['text'] = df_train['text'].str.replace(r'[^\\w\\s]+', '')\n",
    "#df_train['text'] = df_train['text'].apply(\n",
    " #      lambda x: ' '.join([word for word in x.split() if word not in stop]))\n",
    "\n",
    "df_test = pd.read_csv(DATA_PATH+'test.csv')\n",
    "df_test['text'] = df_test['text'].str.replace(r'[^\\w\\s]+', '')\n",
    "df_test['text'] = df_test['text'].apply(\n",
    "        lambda x: ' '.join([word for word in x.split() if word not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['labels'])\n",
    "y_test = le.fit_transform(df_test['labels'])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "np.save(DATA_PATH+'encoder.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f9197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['text']\n",
    "X_test = df_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb2be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_tok, ids, segments = tokenize(X_train, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, min_delta=0.02, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet.fit(x=inp_tok, y=y_train, epochs=2, batch_size=8, validation_split=.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0691385",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet.save_weights(MODEL_PATH+\"xlnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70484446",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(xlnet.optimizer.learning_rate, 1e-5)\n",
    "xlnet.fit(x=inp_tok, y=y_train, epochs=1, batch_size=32, validation_split=.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet.save_weights(MODEL_PATH+\"xlnet_finetuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(xlnet.optimizer.learning_rate, 1e-6)\n",
    "xlnet.fit(x=inp_tok, y=y_train, epochs=1, batch_size=32, validation_split=.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet.save_weights(MODEL_PATH+\"xlnet_finetuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(xlnet.optimizer.learning_rate, 5e-7)\n",
    "xlnet.fit(x=inp_tok, y=y_train, epochs=1, batch_size=32, validation_split=.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(xlnet.optimizer.learning_rate, 1e-7)\n",
    "xlnet.fit(x=inp_tok, y=y_train, epochs=2, batch_size=32, validation_split=.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet.save_weights(MODEL_PATH+\"xlnet_finetuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb01153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet.load_weights(MODEL_PATH+\"xlnet_finetuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e888729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_tok, ids, segments = tokenize(X_test, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47eea25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.classes_ = np.load(MODEL_PATH+'encoder.npy', allow_pickle=True)\n",
    "y_test = encoder.transform(df_test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03ac4152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3983/3983 [==============================] - 10543s 3s/step\n"
     ]
    }
   ],
   "source": [
    "preds = xlnet.predict(inp_tok, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecc343e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2db7882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaccuracy:  0.6  Precision:  0.6289577022194807  Recall:  0.5980899359034344 F1_Score:  0.6069967279947932\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds, average='macro')\n",
    "precision = precision_score(y_test, preds, average='macro')\n",
    "f1 = f1_score(y_test, preds, average='macro')\n",
    "print(\"Aaccuracy: \", accuracy, \" Precision: \", precision ,\" Recall: \", recall, \"F1_Score: \", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
